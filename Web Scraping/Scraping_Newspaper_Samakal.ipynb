{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b33826a",
   "metadata": {},
   "source": [
    "# Webscraping using Selenium and Beautiful Soup\n",
    "## Newspaper: [Samakal](https://en.samakal.com/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c71a2a",
   "metadata": {},
   "source": [
    "#### Task Summary:\n",
    "1. Collected all article links from [here](https://en.samakal.com/search?q=road+accident) using [Instant Data Scraper](https://en.samakal.com/search?q=road+accident) ans saved it as a .csv file.\n",
    "2. Scraped information from the links using Selenium and BeautifulSoup as the website contains Javascript.\n",
    "3. Stored the data in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d039a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url):\n",
    "        \"\"\"\n",
    "        Function which will retrieve a website having javascript from the given URL using selenium webdriver and make a Beautifulsoup object\n",
    "        \"\"\"\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_driver_path=\"C:\\Development\\chromedriver.exe\"\n",
    "        driver = webdriver.Chrome(executable_path=chrome_driver_path,options=chrome_options)\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "        page_source=driver.page_source\n",
    "        bs = BeautifulSoup(page_source, 'html.parser')\n",
    "        driver.close()\n",
    "        return bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f583fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = df.links\n",
    "\n",
    "headings=[]\n",
    "published_time=[]\n",
    "full_text = []\n",
    "i=0\n",
    "for link in links:\n",
    "        i+=1\n",
    "        URL = link\n",
    "        soup = getPage(URL)\n",
    "        \n",
    "        heading=soup.select_one('h1.detail-headline').get_text()\n",
    "        date=soup.select_one('span.detail-time').get_text()        \n",
    "        text=soup.select_one('div.description').get_text()\n",
    "        \n",
    "        headings.append(heading)\n",
    "        published_time.append(date)\n",
    "        full_text.append(text)\n",
    "        print(i)\n",
    "       \n",
    "        \n",
    "df['description_text']=headings\n",
    "df['published_time']=published_time\n",
    "df['full_text'] = full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc40ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(row):\n",
    "    words=row['published_time'].split(\" \")[2:5]\n",
    "    row['published_time']= \" \".join(words)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df.copy()\n",
    "df_2=df_2.apply(clean_date,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(row):\n",
    "    para=row['full_text'].strip(\"\\n\\ufeff\")\n",
    "    row[\"full_text\"]=\" \".join(para.split(\"\\n\\n\"))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1803d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df_2.apply(clean_description,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695650e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('samakal.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9066843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
